{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostgreSQL Database Creation\n",
    "\n",
    "The purpose of this notebook is to use gathered data to create a PostgreSQL database of information for the years 1998-2016. The included tables should include (this list may expand with time):\n",
    "\n",
    "* People (from Lahman DB)\n",
    "* Batting (from Lahman DB)\n",
    "* Pitching (from Lahman DB)\n",
    "* Salary (from Lahman DB)\n",
    "* Appearances (from Lahman DB)\n",
    "* Team data (from Lahman DB)\n",
    "* Payrolls (scraped from The Baseball Cube)\n",
    "* Team WAR by Position (scraped from Fangraphs)\n",
    "* Free Agent Data (scraped from Baseball Reference)\n",
    "\n",
    "**A Clarification on Date:**\n",
    "\n",
    "When I say a year (e.g. \"1998\"), what I mean is that the free agents are those immediately AFTER that season. So for instance, the \"1998\" data should be:\n",
    "\n",
    "* Player's stats for the 1998 season\n",
    "* Player's salary for the 1998 season\n",
    "* Team payroll data from the 1998 season\n",
    "* Team WAR by position for the 1998 season\n",
    "* Free agent information for the 1998 season\n",
    "\n",
    "We're then predicting where free agents will sign for the following season; so the above data would be used to predict free agent destinations for the 1999 season. Thus, the most recent season would be labeled \"2016\" and would be used to predict where free agents ended up for the 2017 season. \n",
    "\n",
    "** Data Limitations **\n",
    "\n",
    "We're going to do 1998-2016 and not the other years. The 2 reasons are:\n",
    "\n",
    "* We can't do 2017 because it's not complete yet; we could certainly predict the destinations for every free agent (and maybe that'll be the final product??), but right now we can't use them for testing. So they're not in the test/train set\n",
    "\n",
    "* We shouldn't do pre-1998 because all of the teams weren't around until 1998, greatly affecting the environment. Furthermore, even though all the teams popped up in 1998, there was an expansion draft that really screwed everything up. So nothing pre-1998\n",
    "\n",
    "That said, we'll capture stats and whatnot INCLUDING 2017 so that we could predict for that year. No point in ignoring those data, we'll just have to screen them out when we pull data from the database later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Establish the PostgreSQL connection and create the database\n",
    "\n",
    "For now, let's create the database locally; we can mess with this later if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://postgres:S%40ndw1ches@localhost:5432/mlb_fa_db\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "# Set postgres username/password, and connection specifics\n",
    "username = 'postgres'\n",
    "password = 'S@ndw1ches'     # change this\n",
    "host     = 'localhost'\n",
    "port     = '5432'            # default port that postgres listens on\n",
    "db_name  = 'mlb_fa_db'\n",
    "\n",
    "engine = create_engine( 'postgresql://{}:{}@{}:{}/{}'.format(username, password, host, port, db_name) )\n",
    "print(engine.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a local database called \"mlb_fa_db\" for storing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Load all our data sources (no postseason)\n",
    "\n",
    "We've got our list of 9 data sources; truth be told, there's more than that if we use postseason stats, but we'll go by category for now. The non-Lahman Data were all pickled by the other notebook; the Lahman data was trimmed, but it was a simple operation we can repeat\n",
    "\n",
    "### 1-6 Load the Lahman Data\n",
    "\n",
    "First, we'll load everything, then we'll trim to just 1998 forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the CSV files\n",
    "all_batting = pd.read_csv(\"../baseballdatabank/core/Batting.csv\")\n",
    "all_pitching = pd.read_csv(\"../baseballdatabank/core/Pitching.csv\")\n",
    "all_salary = pd.read_csv(\"../baseballdatabank/core/Salaries.csv\")\n",
    "all_people = pd.read_csv(\"../baseballdatabank/core/People.csv\")\n",
    "all_appearances = pd.read_csv(\"../baseballdatabank/core/Appearances.csv\")\n",
    "all_teams = pd.read_csv(\"../baseballdatabank/core/Teams.csv\")\n",
    "\n",
    "# Cut off the year at 1998 for the ones that works for\n",
    "# We'll screen out years without player IDs in the first 5 DFs\n",
    "batting_1998, pitching_1998, salary_1998, teams_1998, appearances_1998 = [\n",
    "df[df.yearID >= 1998] for df in [all_batting, all_pitching, all_salary, all_teams, all_appearances]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Screen out the pre-1998 people too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-9 Load the pickle files\n",
    "\n",
    "We've got 4 pickle files (2 for Team WAR) that we'll just load here. They should be pretty ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the Position Player Team WAR\n",
    "with open('position_war.pickle', 'rb') as file:\n",
    "    position_war = pickle.load(file)\n",
    "\n",
    "# Load the Pitcher Team WAR\n",
    "with open('pitcher_war.pickle', 'rb') as file:\n",
    "    pitcher_war = pickle.load(file)\n",
    "\n",
    "# Load the Team Payroll Data\n",
    "with open(\"team_payrolls.pickle\", 'rb') as file:\n",
    "    team_payrolls = pickle.load(file)\n",
    "\n",
    "# Load the Free Agent data\n",
    "with open(\"free_agents.pickle\", \"rb\") as file:\n",
    "    free_agents = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Write each data frame to sql\n",
    "\n",
    "Here is what is in the Dev Setup that I can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## insert data into database from Python (proof of concept - this won't be useful for big data, of course)\n",
    "birth_data.to_sql('birth_data_table', engine, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
