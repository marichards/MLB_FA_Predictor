{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assemble the Features\n",
    "\n",
    "We want to assemble our data in to a data frame of features; for now I'm going to try to make something including:\n",
    "\n",
    "* Position player performance data (~3 numbers)\n",
    "* Position player position\n",
    "* Team salary data\n",
    "* Team performance for position (previous year)\n",
    "* Team value lost for position (from previous year, using FAs)\n",
    "\n",
    "We'll try doing it in stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bring in packages and connect to database\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Set postgres username/password, and connection specifics\n",
    "username = 'postgres'\n",
    "password = 'S@ndw1ches'     # change this\n",
    "host     = 'localhost'\n",
    "port     = '5432'            # default port that postgres listens on\n",
    "db_name  = 'mlb_fa_db'\n",
    "\n",
    "engine = create_engine( 'postgresql://{}:{}@{}:{}/{}'.format(username, password, host, port, db_name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a quick querying function\n",
    "def pullFullTable(table, engine):\n",
    "    '''Quick little function for pulling a full table'''\n",
    "    \n",
    "    query = 'select * from {}'.format(table)\n",
    "    \n",
    "    # Execute the query with context manager\n",
    "    with engine.connect() as con:\n",
    "        results = con.execute(query)\n",
    "        fetched_data = pd.DataFrame(results.fetchall())\n",
    "        fetched_data.columns = results.keys()\n",
    "        \n",
    "    return fetched_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Grab Batting data and filter it by only free agents\n",
    "\n",
    "We'll do it in 5 stages:\n",
    "\n",
    "1. Pull batting data and shorten its columns to just the ones I want\n",
    "2. Pull the \"people\" data to get the first/last names for batting data\n",
    "3. Join batting and people to get all the data JUST for our desired years\n",
    "3. Pull the \"free_agents\" data\n",
    "5. Join \"batting\" and new free_agents/people to filter batting by only free agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['free_agents', 'pitching', 'batting', 'salary', 'people', 'position_team_war', 'appearances', 'teams', 'pitcher_team_war', 'payrolls']\n"
     ]
    }
   ],
   "source": [
    "print(engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>playerID</th>\n",
       "      <th>yearID</th>\n",
       "      <th>stint</th>\n",
       "      <th>teamID</th>\n",
       "      <th>lgID</th>\n",
       "      <th>G</th>\n",
       "      <th>AB</th>\n",
       "      <th>R</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SB</th>\n",
       "      <th>CS</th>\n",
       "      <th>BB</th>\n",
       "      <th>SO</th>\n",
       "      <th>IBB</th>\n",
       "      <th>HBP</th>\n",
       "      <th>SH</th>\n",
       "      <th>SF</th>\n",
       "      <th>GIDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76643</td>\n",
       "      <td>abbotje01</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>89</td>\n",
       "      <td>244</td>\n",
       "      <td>33</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76644</td>\n",
       "      <td>abbotji01</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76645</td>\n",
       "      <td>abbotku01</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>OAK</td>\n",
       "      <td>AL</td>\n",
       "      <td>35</td>\n",
       "      <td>123</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76646</td>\n",
       "      <td>abbotku01</td>\n",
       "      <td>1998</td>\n",
       "      <td>2</td>\n",
       "      <td>COL</td>\n",
       "      <td>NL</td>\n",
       "      <td>42</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76647</td>\n",
       "      <td>abbotpa01</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>SEA</td>\n",
       "      <td>AL</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   playerID  yearID  stint teamID lgID   G   AB   R   H  ...    RBI  \\\n",
       "0  76643  abbotje01    1998      1    CHA   AL  89  244  33  68  ...   41.0   \n",
       "1  76644  abbotji01    1998      1    CHA   AL   5    0   0   0  ...    0.0   \n",
       "2  76645  abbotku01    1998      1    OAK   AL  35  123  17  33  ...    9.0   \n",
       "3  76646  abbotku01    1998      2    COL   NL  42   71   9  18  ...   15.0   \n",
       "4  76647  abbotpa01    1998      1    SEA   AL   4    0   0   0  ...    0.0   \n",
       "\n",
       "    SB   CS  BB    SO  IBB  HBP   SH   SF  GIDP  \n",
       "0  3.0  3.0   9  28.0  1.0  0.0  2.0  5.0   2.0  \n",
       "1  0.0  0.0   0   0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "2  2.0  1.0  10  34.0  0.0  1.0  1.0  1.0   3.0  \n",
       "3  0.0  0.0   2  19.0  0.0  1.0  0.0  2.0   2.0  \n",
       "4  0.0  0.0   0   0.0  0.0  0.0  0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our query\n",
    "batting_data = pullFullTable('batting', engine)\n",
    "    \n",
    "batting_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop non-numeric team/league columns\n",
    "batting_data.drop(['teamID','lgID'], axis = 1)\n",
    "\n",
    "# Add data from players who had multiple stints and \n",
    "batting_totals = batting_data.groupby(['playerID','yearID'], as_index= False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25365, 7)\n",
      "    playerID  yearID   G  OBP  SLG  HR  RBI\n",
      "0  aardsda01    2004  11  0.0  0.0   0  0.0\n",
      "1  aardsda01    2006  45  0.0  0.0   0  0.0\n",
      "2  aardsda01    2007  25  0.0  0.0   0  0.0\n",
      "3  aardsda01    2008  47  0.0  0.0   0  0.0\n",
      "4  aardsda01    2009  73  0.0  0.0   0  0.0\n",
      "        playerID  yearID    G       OBP       SLG  HR    RBI\n",
      "18417  pujolal01    2001  161  0.402963  0.610169  37  130.0\n",
      "18418  pujolal01    2002  157  0.394074  0.561017  34  127.0\n",
      "18419  pujolal01    2003  157  0.439416  0.666667  43  124.0\n",
      "18420  pujolal01    2004  154  0.414740  0.657095  46  123.0\n",
      "18421  pujolal01    2005  161  0.430000  0.609137  41  117.0\n",
      "18422  pujolal01    2006  143  0.430599  0.671028  49  137.0\n",
      "18423  pujolal01    2007  158  0.428571  0.568142  32  103.0\n",
      "18424  pujolal01    2008  148  0.461778  0.652672  37  116.0\n",
      "18425  pujolal01    2009  160  0.442857  0.658451  47  135.0\n",
      "18426  pujolal01    2010  159  0.414286  0.596252  42  118.0\n",
      "18427  pujolal01    2011  147  0.365591  0.540587  37   99.0\n",
      "18428  pujolal01    2012  154  0.343284  0.515651  30  105.0\n",
      "18429  pujolal01    2013   99  0.329571  0.437340  17   64.0\n",
      "18430  pujolal01    2014  159  0.323741  0.466035  28  105.0\n",
      "18431  pujolal01    2015  157  0.307110  0.480066  40   95.0\n",
      "18432  pujolal01    2016  152  0.323077  0.456998  31  119.0\n",
      "18433  pujolal01    2017  149  0.286164  0.386172  23  101.0\n"
     ]
    }
   ],
   "source": [
    "# Create new variables and select only them (fill NaN with 0)\n",
    "batting_totals['OBP'] = (batting_totals['H'] + \n",
    "                       batting_totals['BB'] + \n",
    "                       batting_totals['HBP']).divide(batting_totals['AB'] + \n",
    "                                                   batting_totals['BB'] + \n",
    "                                                   batting_totals['HBP'] + \n",
    "                                                   batting_totals['SF']).fillna(0)\n",
    "\n",
    "batting_totals['SLG'] = (batting_totals['H'] + \n",
    "                         batting_totals['2B'] + \n",
    "                         2 * batting_totals['3B'] + \n",
    "                         3 * batting_totals['HR']).divide(batting_totals['AB']).fillna(0)\n",
    "\n",
    "batting_trimmed = batting_totals[['playerID', 'yearID', 'G', 'OBP', 'SLG', 'HR', 'RBI']]\n",
    "\n",
    "# Fill \"NaN\" values for OBP/SLG with 0\n",
    "print(batting_trimmed.shape)\n",
    "print(batting_trimmed.head())\n",
    "print(batting_trimmed[batting_trimmed['playerID'] == 'pujolal01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25365, 7)\n",
      "    playerID  yearID         G       OBP       SLG        HR       RBI\n",
      "0  aardsda01    2004 -0.926802 -1.128818 -1.021286 -0.520478 -0.613383\n",
      "1  aardsda01    2006 -0.223818 -1.096651 -1.018416 -0.510545 -0.606120\n",
      "2  aardsda01    2007 -0.623055 -1.074030 -0.948662 -0.505253 -0.600185\n",
      "3  aardsda01    2008 -0.146466 -1.085320 -0.912276 -0.496440 -0.599853\n",
      "4  aardsda01    2009  0.388188 -1.070321 -1.006028 -0.506939 -0.601370\n",
      "        playerID  yearID         G       OBP       SLG        HR       RBI\n",
      "18417  pujolal01    2001  2.193543  1.141557  1.615230  3.637957  3.709145\n",
      "18418  pujolal01    2002  2.089353  1.156760  1.559438  3.652412  3.852653\n",
      "18419  pujolal01    2003  2.102354  1.271069  1.857574  4.707794  3.641002\n",
      "18420  pujolal01    2004  2.069087  1.336778  1.943523  4.956622  3.615371\n",
      "18421  pujolal01    2005  2.189724  1.362913  1.529887  4.658596  3.554547\n",
      "18422  pujolal01    2006  1.802831  1.322061  1.937764  5.258251  3.979439\n",
      "18423  pujolal01    2007  2.149787  1.308964  1.405410  3.663164  2.949472\n",
      "18424  pujolal01    2008  2.002254  1.479137  1.758056  4.364865  3.570410\n",
      "18425  pujolal01    2009  2.216923  1.464446  2.100880  5.475587  4.209536\n",
      "18426  pujolal01    2010  2.222585  1.280402  1.612431  5.248734  3.834918\n",
      "18427  pujolal01    2011  2.043980  1.008255  1.555847  4.733167  3.286667\n",
      "18428  pujolal01    2012  2.159915  1.032390  1.540237  3.479242  3.453992\n",
      "18429  pujolal01    2013  0.988854  0.984588  1.236602  1.957101  1.994369\n",
      "18430  pujolal01    2014  2.289193  0.939020  1.400173  3.911971  3.806011\n",
      "18431  pujolal01    2015  2.242632  0.761801  1.195158  5.015800  3.243336\n",
      "18432  pujolal01    2016  2.141428  0.906959  1.139770  3.259550  3.896376\n",
      "18433  pujolal01    2017  2.093943  0.632916  0.768528  2.137278  3.150277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matt/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:2352: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "# Standardize the numerical columns by year\n",
    "numerical = ['G', 'OBP', 'SLG', 'HR', 'RBI']\n",
    "\n",
    "batting_trimmed[numerical] = batting_trimmed.groupby('yearID')[numerical].transform(zscore)\n",
    "\n",
    "# Take a look at the output\n",
    "print(batting_trimmed.shape)\n",
    "print(batting_trimmed.head())\n",
    "print(batting_trimmed[batting_trimmed['playerID'] == 'pujolal01'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll pull the People and Free Agents and join People to Batting, and \n",
    "\n",
    "Note: I tried to do the join directly with SQL and it got mad, so I'm going to do it here instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 0 elements, new values have 25 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-5dea70d2b5b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Bring in people and free agents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpeople\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpullFullTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'people'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfree_agents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpullFullTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'free_agents'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeople\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfree_agents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-162-321b94f1d85f>\u001b[0m in \u001b[0;36mpullFullTable\u001b[0;34m(table, engine)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfetched_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mfetched_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   3092\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3093\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3094\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3095\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3096\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m   2834\u001b[0m             raise ValueError('Length mismatch: Expected axis has %d elements, '\n\u001b[1;32m   2835\u001b[0m                              \u001b[0;34m'new values have %d elements'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2836\u001b[0;31m                              (old_len, new_len))\n\u001b[0m\u001b[1;32m   2837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 0 elements, new values have 25 elements"
     ]
    }
   ],
   "source": [
    "# Bring in people and free agents\n",
    "people = pullFullTable('people', engine)\n",
    "free_agents = pullFullTable('free_agents', engine)\n",
    "\n",
    "print(people.shape, free_agents.shape)\n",
    "print(people.columns, free_agents.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join people to batting, adding ONLY nameLast/nameFirst\n",
    "people_trimmed = people[['playerID', 'nameFirst', 'nameLast']]\n",
    "\n",
    "batting_w_people = pd.merge(batting_trimmed, people_trimmed, on = 'playerID', how = 'inner')\n",
    "print(batting_w_people.shape)\n",
    "print(batting_w_people.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_agents.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join based on nameFirst/nameLast\n",
    "free_agents_batting = pd.merge(free_agents, batting_w_people, \n",
    "                               left_on = ['nameFirst', 'nameLast', 'Year'],\n",
    "                               right_on = ['nameFirst', 'nameLast', 'yearID'])\n",
    "print(free_agents_batting.shape)\n",
    "print(free_agents_batting.columns)\n",
    "print(free_agents_batting.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out only the desired columns\n",
    "free_agents_batting = free_agents_batting.drop(['index', 'Full_Name', 'Year'], axis = 1)\n",
    "print(free_agents_batting.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Add positions\n",
    "\n",
    "This will require data from our new \"free_agents_batting\" and \"appearances\". Basically:\n",
    "\n",
    "* Pull appearances data\n",
    "* Collapse \"appearances\" data into positions\n",
    "* Join it with free_agents_batting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in Appearances data to add positions\n",
    "appearances = pullFullTable('appearances', engine)\n",
    "    \n",
    "print(appearances.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset to only positional data and group by playerID/yearID\n",
    "appearances_compact = appearances.drop(['index', 'teamID','lgID', 'G_batting', \n",
    "                                        'G_defense','G_all','GS', 'G_ph', 'G_pr'], \n",
    "                                       axis = 1).groupby(['playerID','yearID'], \n",
    "                                                         as_index = False).sum()\n",
    "\n",
    "# Check data\n",
    "print(appearances_compact.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out primary position by melting, then grouping and finding the max value\n",
    "appearances_melt = pd.melt(appearances_compact, id_vars= ['playerID', 'yearID'],\n",
    "                           value_name = 'Games', var_name = 'Position')\n",
    "print(appearances_melt[appearances_melt['playerID'] == 'clontbr01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the index for the maximum games\n",
    "primary_idx = appearances_melt.groupby(['playerID','yearID'])['Games'].idxmax()\n",
    "\n",
    "# Use it to screen out the proper rows\n",
    "primary_position = appearances_melt.loc[primary_idx]\n",
    "\n",
    "# Turn the \"Position\" Column into the right contents by pulling just the position and capitalizing\n",
    "primary_position['Position'] = primary_position.Position.str.split(\"_\").str.get(1).str.upper()\n",
    "print(primary_position[primary_position['playerID'] == 'clontbr01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the join on the 6202 x 13 free_agents_batting\n",
    "# Join based on nameFirst/nameLast\n",
    "fa_bat_pos = pd.merge(free_agents_batting, primary_position, \n",
    "                      on = ['playerID', 'yearID']).drop(['Games'], axis = 1)\n",
    "print(fa_bat_pos.head(10))\n",
    "print(fa_bat_pos.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 Add Team WAR for position\n",
    "\n",
    "Basically I see this as:\n",
    "\n",
    "1. Load the Team WAR data\n",
    "2. Change column names to be more concise\n",
    "3. Join it to the existing data frame using yearID + position. This should necessarily remove pitchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the data but drop the index\n",
    "position_war = pullFullTable('position_team_war', engine).drop(['index'], axis = 1)\n",
    "print(position_war.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Year to a date-time and call it \"yearID\"\n",
    "position_war['yearID'] = position_war.Year\n",
    "position_war = position_war.drop(['Year'], axis = 1)\n",
    "print(position_war.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for converting these to abbreviations\n",
    "team_dict = {'Angels' : 'LAA', 'Astros' : 'HOU', 'Athletics' : 'OAK', 'Blue Jays' : 'TOR', \n",
    "             'Braves' : 'ATL', 'Brewers': 'MIL', 'Cardinals' : 'STL', 'Cubs' : 'CHN',\n",
    "             'Diamondbacks' : 'ARI', 'Dodgers' : 'LAN', 'Giants' : 'SFN', 'Indians' : 'CLE',\n",
    "             'Mariners' : 'SEA', 'Marlins' : 'MIA', 'Mets' : 'NYN', 'Nationals' : 'WAS',\n",
    "             'Orioles' : 'BAL', 'Padres' : 'SDN', 'Phillies' : 'PHI', 'Pirates' : 'PIT', \n",
    "             'Rangers' : 'TEX', 'Rays' : 'TBR', 'Red Sox' : 'BOS', 'Reds' : 'CIN', \n",
    "             'Rockies' : 'COL', 'Royals' : 'KCR', 'Tigers' : 'DET', 'Twins' : 'MIN', \n",
    "             'White Sox' : 'CHA', 'Yankees' : 'NYA'}\n",
    "\n",
    "# Alter it to include WAR\n",
    "team_dict = {key : value + \"_WAR\" for key, value in team_dict.items()}\n",
    "print(team_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_war = position_war.rename(columns = team_dict)\n",
    "print(position_war.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_war.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now add these WAR data to the batting data, by position/year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_bat_pos.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_bat_pos['Position'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALERT ALERT: Grab Pitcher info and add in to fix this!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the 2 data frames\n",
    "# This is only the ~2350 position players for now; do a left join\n",
    "fa_bat_team_war = pd.merge(fa_bat_pos, position_war, how = 'left',\n",
    "                           on = ['Position', 'yearID'], )\n",
    "\n",
    "print(fa_bat_team_war.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task ???: Pull Team data\n",
    "\n",
    "Pull this to help with team -> teamID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column names to team abbreviations using Team Data\n",
    "teams = pullFullTable('teams', engine)\n",
    "print(teams.head())\n",
    "print(list(teams.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull just a handful of these columns (W, G, teamID, name, yearID)\n",
    "teams_short = teams[['yearID', 'teamID', 'name', 'W', 'G']]\n",
    "teams_short['teamID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert altered names/teamID \n",
    "name_change = {'Anaheim Angels': 'Los Angeles Angels of Anaheim', \n",
    "                   'Tampa Bay Devil Rays' : 'Tampa Bay Rays',\n",
    "                   'Montreal Expos' : 'Washington Nationals', \n",
    "                   'Florida Marlins' : 'Miami Marlins'\n",
    "                  }\n",
    "    \n",
    "origin_change = {'ANA': 'LAA', 'TBD':'TBR', 'MON':'WAS', 'FLO':'MIA'}\n",
    "\n",
    "teams_short['name'] = teams_short['name'].replace(name_change)\n",
    "teams_short['teamID'] = teams_short['teamID'].replace(origin_change)\n",
    "\n",
    "# Change W/G to W_Pct\n",
    "    \n",
    "teams_short['W_Pct'] = teams_short['W'].divide(teams_short.G)\n",
    "\n",
    "teams_short = teams_short.drop(['W','G'], axis = 1)\n",
    "\n",
    "teams_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_short.name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next task: Use these data to change the free_agents data a bit\n",
    "\n",
    "We need to convert the Destination data from free_agents...this is where to do it!\n",
    "\n",
    "*This will also remove the FAs without teams*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check destination data\n",
    "fa_bat_team_war.Destination.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix the weird angels data\n",
    "fa_bat_team_war['Destination'] = fa_bat_team_war['Destination'].replace({'Los Angeles Angels' :\n",
    "                                                                         'Los Angeles Angels of Anaheim'})\n",
    "fa_bat_team_war.Destination.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a join to the sub-team DF\n",
    "team_translate = teams_short[['teamID', 'name']].drop_duplicates()\n",
    "\n",
    "\n",
    "fa_bat_team_war_teamID = pd.merge(fa_bat_team_war, team_translate, how = 'left',\n",
    "                          left_on = ['Destination'], right_on = ['name'])\n",
    "\n",
    "# Substitute the Destination Column with the info from teamID and drop teamID\n",
    "fa_bat_team_war_teamID['Destination'] = fa_bat_team_war_teamID['teamID']\n",
    "fa_bat_team_war_teamID = fa_bat_team_war_teamID.drop(['teamID'], axis = 1)\n",
    "fa_bat_team_war_teamID.drop_duplicates().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Use payroll data to cluster teams\n",
    "\n",
    "Now I need to use payroll data to create clusters of teams. So I'll:\n",
    "\n",
    "1. Load the payroll data\n",
    "2. Standardize it for each year\n",
    "3. Run it through clustering\n",
    "4. Use cluster labels to create a translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load payroll data\n",
    "payrolls = pullFullTable('payrolls', engine)\n",
    "payrolls.set_index('Year', inplace=True)\n",
    "payrolls.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose the data and standardize it\n",
    "payrolls_transposed = payrolls.transpose()\n",
    "payrolls_transposed_standard = payrolls_transposed.transform(zscore)\n",
    "payrolls_transposed_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster them via hierarchical clustering\n",
    "\n",
    "# Perform the necessary imports\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the linkage: mergings\n",
    "mergings = linkage(payrolls_transposed_standard.values, method = 'complete')\n",
    "\n",
    "# Plot the dendrogram, using varieties as labels\n",
    "dendrogram(mergings,\n",
    "           labels=list(payrolls_transposed_standard.index),\n",
    "           leaf_rotation=90,\n",
    "           leaf_font_size=6,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select clusters using maximum height of 6\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "# Use fcluster to extract labels: labels\n",
    "labels = fcluster(mergings, 6, criterion = 'distance')\n",
    "\n",
    "\n",
    "label_data = pd.DataFrame({'label' : labels, 'Team' : list(payrolls_transposed_standard.index)})\n",
    "\n",
    "label_data.sort_values('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join this to the existing data\n",
    "label_data['Team'] = label_data.replace({'Los Angeles Angels':\n",
    "                                         'Los Angeles Angels of Anaheim'})\n",
    "\n",
    "labels_as_teamID = pd.merge(label_data, team_translate, \n",
    "                            left_on = ['Team'], right_on = ['name'])[['teamID', 'label']]\n",
    "fa_with_clusters = pd.merge(fa_bat_team_war_teamID, labels_as_teamID,\n",
    "                            left_on = ['Destination'], right_on = ['teamID'])\n",
    "fa_with_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster them via DBscan\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "db = DBSCAN(eps=0.1).fit(payrolls_transposed_standard.values)\n",
    "\n",
    "labels = db.labels_\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Task: Save the data\n",
    "\n",
    "For now, save a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "test_set = fa_with_clusters.dropna()\n",
    "final_data = test_set\n",
    "\n",
    "final_data.to_pickle('final_data.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with Standardizing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful plots\n",
    "\n",
    "Things I could plot:\n",
    "\n",
    "* Player contract vs WAR\n",
    "* Player contract vs Age"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
